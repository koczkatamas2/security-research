Exploit Details
===============

Exploit demo for CVE-2023-31436.
Flag: `kernelCTF{v1:mitigation-6.1-v2:1688980403:8075e41586a95a7128a3f9feb6dfddd242bcc92d}`

# Summary

At a high level the exploit performs the following:

- Spray QFQ qdiscs along with user controlled buffers into `dyn-kmalloc-8192`
- Spray user controlled objects into `kmalloc-128`
- Trigger the vulnerability into one user controlled buffer, leaving us with a controllable `struct qfq_group` object
- Use the controlled `struct qfq_group` object to corrupt the `struct qfq_sched->filter_list` member so that it
  points to our user controlled object in `kmalloc-128`

Note: The original exploit targeted the `mitigation-6.1-broken` instance, it was later modified to work on `mitigation-6.1-v2`.

# Steps in Detail

## Step 1: Abusing the Vulnerability

Triggering the vulnerability is trivial, though actually taking something useful
out of the out-of-bounds group is not obvious.
Even though the pointer is used in a few places I only identified two places which
seem particularly interesting from a exploitation perspective:
```c
static void qfq_slot_insert(struct qfq_group *grp, struct qfq_aggregate *agg,
			    u64 roundedS)
{
// ...
	hlist_add_head(&agg->next, &grp->slots[i]); // [1.1]
	__set_bit(slot, &grp->full_slots);          // [1.2]
}


static void qfq_schedule_agg(struct qfq_sched *q, struct qfq_aggregate *agg)
{
	struct qfq_group *grp = agg->grp;
// ...
	s = qfq_calc_state(q, grp);
	__set_bit(grp->index, &q->bitmaps[s]); // [2]
// ...
}
```

Looking at `qfq_slot_insert` we can see that we can write a pointer to a aggregate
into the slots array [1.1]. Controlling `i` is not trivial, but may be possible.
This way we can potentially write a pointer into a following object in the `dyn-kmalloc-8192`
slab.
Eventually this could lead to a UaF scenario after the aggregate is destroyed.
Due to the complexities involved in controlling the index along with the correct
alignment I decided against this path.

This leaves us with a bit set operation at a controlled index [2].
The idea will be to flip a bit on a pointer to eventually cause a type confusion.
Looking at the `struct qfq_sched` we can see that there are only few members
available to us after the `bitmaps[]` member (we cannot use a negative index).

```c
struct qfq_sched {
	struct tcf_proto __rcu *filter_list;
	struct tcf_block	*block;
	struct Qdisc_class_hash clhash;

	u64			oldV, V;	/* Precise virtual times. */
	struct qfq_aggregate	*in_serv_agg;   /* Aggregate being served. */
	u32			wsum;		/* weight sum */
	u32			iwsum;		/* inverse weight sum */

	unsigned long bitmaps[QFQ_MAX_STATE];	    /* Group bitmaps. */
	struct qfq_group groups[QFQ_MAX_INDEX + 1]; /* The groups. */
	u32 min_slot_shift;	/* Index of the group-0 bit in the bitmaps. */

	u32 max_agg_classes;		/* Max number of classes per aggr. */
	struct hlist_head nonfull_aggs; /* Aggs with room for more classes. */
};
```

The `nonfull_aggs` member is interesting as this list will be used to lookup
aggregates when creating new classes:
```c
static struct qfq_aggregate *qfq_find_agg(struct qfq_sched *q,
					  u32 lmax, u32 weight)
{
	struct qfq_aggregate *agg;

	hlist_for_each_entry(agg, &q->nonfull_aggs, nonfull_next)
		if (agg->lmax == lmax && agg->class_weight == weight)
			return agg;

	return NULL;
}
```
Originally I planned to smuggle a fake `qfq_aggregate` into the qdisc which is
hopefully freed when destroying the class that possesses it.
This way we can have a UaF in the `kmalloc-128` slab.
Anyway I could not find a suitable object which would allow us to control all the
relevant members (`lmax`, `class_weight`, `num_classes`).
Therefor we will try to flip a bit on an object after the qdisc.
Naturally this will be the object that we used to create the fake group, however
the following seemed easier (though less stable):

```

+-qfq qdisc----+
| ...          |
| filter_list  | ---------------------+
| ...          |                      +-----> 0100 +-tcf_proto-+
| bitmaps[]    |                                   |           |
| groups[]     |                                   |           |
| ...          |                                   +-----------+
+--------------+
                                              0180 +-fake obj--+
+-controlled o-+                                   |           +
| ...          |                                   |           +
| fake grp {}  |                                   +-----------+
|              |
| ...          |         +---x--------------> 0200 +-tcf_proto-+
| ...          |         |   x                     |           |
|              |         |   x flip                |           |
+--------------+         |   x a bit               +-----------+
                         |   x
+-qfq qdisc----+         |   x--------------> 0280 +-fake obj--+
| ...          |         |                         |           |
| filter_list  | --------+                         |           |
| ...          |                                   +-----------+
| bitmaps[]    |
| groups[]     |                              0300 +-fake obj--+
| ...          |                                   |           |
+--------------+                                   |           |
                                                   +-----------+
```

By targeting a bit of the `filter_list` member of the qdisc after the user controlled
object we will potentially be able to inject a malicious `struct tcf_proto` object
into the qdisc.
This object can be abused for trivial RIP control via the `classify()` member,
which will be called in `qfq_enqueue`.

```c
// in include/net/sch_generic.h

struct tcf_proto {
	/* Fast access part */
	struct tcf_proto __rcu	*next;
	void __rcu		*root;

	/* called under RCU BH lock*/
	int			(*classify)(struct sk_buff *,
					    const struct tcf_proto *,
					    struct tcf_result *);
	__be16			protocol;

	/* All the rest */
	u32			prio;
	void			*data;
	const struct tcf_proto_ops	*ops;
	struct tcf_chain	*chain;
	/* Lock protects tcf_proto shared state and can be used by unlocked
	 * classifiers to protect their private data.
	 */
	spinlock_t		lock;
	bool			deleting;
	refcount_t		refcnt;
	struct rcu_head		rcu;
	struct hlist_node	destroy_ht_node;
};
```

### Step 1.1: QFQ Internal State Control

Looking at the code in `qfq_change_class()` we can see that `qfq_add_to_agg()`
is called with the new `agg`:

```c
// net/sched/sch_qfq.c

/* Add class to aggregate. */
static void qfq_add_to_agg(struct qfq_sched *q,
			   struct qfq_aggregate *agg,
			   struct qfq_class *cl)
{
	cl->agg = agg;

	qfq_update_agg(q, agg, agg->num_classes+1); // [1]
	if (cl->qdisc->q.qlen > 0) { /* adding an active class */
		list_add_tail(&cl->alist, &agg->active);
		if (list_first_entry(&agg->active, struct qfq_class, alist) ==
		    cl && q->in_serv_agg != agg) /* agg was inactive */
			qfq_activate_agg(q, agg, enqueue); /* schedule agg */   // [2]
	}
}
```

After the out-of-bound group is stored into the aggregate in [1] we can
hit `qfq_activate_agg()` [2].

```c
/* Update agg ts and schedule agg for service */
static void qfq_activate_agg(struct qfq_sched *q, struct qfq_aggregate *agg,
			     enum update_reason reason)
{
	agg->initial_budget = agg->budget = agg->budgetmax; /* recharge budg. */

	qfq_update_agg_ts(q, agg, reason);
	if (q->in_serv_agg == NULL) { /* no aggr. in service or scheduled */
		q->in_serv_agg = agg; /* start serving this aggregate */
		 /* update V: to be in service, agg must be eligible */
		q->oldV = q->V = agg->S;
	} else if (agg != q->in_serv_agg)
		qfq_schedule_agg(q, agg); // [3]
}
```

After passing the checks in `qfq_activate_agg()` we will call the desired
`qfq_schedule_agg()` [3].

In order to hit these code paths we need to fullfill certain constraints:
1. `q->in_serv_agg != NULL` and `q->in_serv_agg != new_oob_agg`
2. (sub) qdisc of the owning class of the aggregate needs to be non-empty (`cl->qdisc->q.qlen > 0`)

We can control `q->in_serv_agg` by enqueuing packets:
```c
static int qfq_enqueue(struct sk_buff *skb, struct Qdisc *sch,
		       struct sk_buff **to_free)
{
// ...
	qfq_activate_agg(q, agg, enqueue);
// ...
}
```
Initially `q->in_serv_agg` will be `NULL`, thus we will hit the second branch
in `qfq_activate_agg()` (see above).

The problem is that, right after enqueuing the packet, the dequeue operation
will reset the state (unless we generate enormous amounts of traffic so that
the scheduling actually kicks in, which however still leaves us with a race).
In order to work around that problem we will modify the sub qdisc of the class
to be a `netem` qdisc, which allows us to add a generously chosen delay, so that
the dequeue operation fails because no packet is available yet.
This will issue a warning in `qfq_peek_skb()`, but that will not be problem for us.

This solves constraint number one. As a bonus this naturally solves constraint
number two because the underlaying netem qdisc has in fact packets queued,
they are just delayed.

### Step 2: Heap Spray

### Step 2.1: QFQ qdiscs and `dyn-malloc-8192`

To successfully make use of the vulnerability we need a controllable object in
the `dyn-kmalloc-8192` cache.

The qdisc is allocated by `qdisc_alloc()`:
```c
// qdisc_alloc() in net/sched/sch_generic.c
	struct Qdisc *sch;

// ..

	dev = dev_queue->dev;
	sch = kzalloc_node(size, GFP_KERNEL, netdev_queue_numa_node_read(dev_queue));
```

This size is a) not compile time constant and b) allocated with `GFP_KERNEL`,
so we need an object which satisfies both as well.

I chose `struct qdisc_size_table`, as it has all those properties:
```c
// qdisc_get_stab() in net/sched/sch_api.c

	struct qdisc_size_table *stab;
// ..
	stab = kmalloc(struct_size(stab, data, tsize), GFP_KERNEL);
```
To get the desired layout, we will allocate one sizetable alongside each qdisc we
spray. This way we hopefully get the desired alternating layout.
One should note, that the different sizetables need not be equal, otherwise no
allocation would be made.

In order to spray the qdiscs we will create child processes, each with a new
network namespace to isolate each qdisc.

### Step 2.2: `struct tcf_proto`s and `kmalloc-128`

As mentioned earlier, we will try to modify the `q->filter_list` member in order to point
to a nearby user controlled object.
`struct tcf_proto` is allocated in `kmalloc-128` with `GFP_KERNEL` so we will need
a similar statically sized object.

I found [XDP](https://www.kernel.org/doc/html/latest/networking/af_xdp.html) to be
very useful for this. Specifically we will use `struct xdp_mem` for this purpose,
as the `void *addrs` member overlays perfectly with the `struct tcf_proto __rcu *next`
member of `struct tcf_proto`:

```c
// in include/net/xdp_sock.h, size = 112 bytes

struct xdp_umem {
	void *addrs;
	u64 size;
	u32 headroom;
	u32 chunk_size;
	u32 chunks;
	u32 npgs;
	struct user_struct *user;
	refcount_t users;
	u8 flags;
	bool zc;
	struct page **pgs;
	int id;
	struct list_head xsk_dma_list;
	struct work_struct work;
};
```

This structure is a nice primitive, as it allows us to create arbitrary kernel objects.
Furthermore we will have arbitrary read / write for the created kernel objects, if we would need it.
`XDP` allows the creation of shared memory buffers between kernel and userspace.
When creating the `AF_XDP` socket and registering the shared memory through `setsockopt()`,
the `addrs` member will be mapped directly to the userspace buffer.
Any code dereferencing this address will therefor use our controlled buffer.
This fits perfectly onto our `struct tcf_proto` as it is implementing a simple
forward list with the first member.

In order to spray those objects, we will simply create many `AF_XDP` sockets and
register memory for each of them.

## Step 3: Getting RIP Control

By constructing a fake `struct tcf_proto` object with a suitable `classify` member
we are on a good way to gain arbitrary kernel code execution:

```c
// in net/sched/sch_qfq.c
static struct qfq_class *qfq_classify(struct sk_buff *skb, struct Qdisc *sch,
				      int *qerr)
{
	struct qfq_sched *q = qdisc_priv(sch);
	struct tcf_proto *fl;
// ..
	fl = rcu_dereference_bh(q->filter_list);
	result = tcf_classify(skb, NULL, fl, &res, false);
// ..
}

// in net/sched/cls_api.c
static inline int __tcf_classify(struct sk_buff *skb,
				 const struct tcf_proto *tp,
				 const struct tcf_proto *orig_tp,
				 struct tcf_result *res,
				 bool compat_mode,
				 u32 *last_executed_chain)
{
// ..
	for (; tp; tp = rcu_dereference_bh(tp->next)) {
		__be16 protocol = skb_protocol(skb, false);
		int err;

		if (tp->protocol != protocol &&
		    tp->protocol != htons(ETH_P_ALL))
			continue;

		err = tp->classify(skb, tp, res);
// ..
}
```

Even though we created a fake object for `kmalloc-128` we do not have any real size
restrictions on the payload.
`tp->classify` is called with the `tp` object as a second parameter (into `rsi`),
which serves as a perfect candidate for a stack pivot onto the fake object.

One downside of the chosen entrypoint into the kernel is the fact, that we are in an
interrupt context. Thus we cannot simply return to usermode naively.
To overcome this issue we will restore the execution right at the end of `qfq_enqueue`
so that the kernel will deal with this problem on its own.
Right as we enter `rbp` will contain a stack pointer.
We copy this pointer to a save location in memory and eventually restore the stack frame.

Besides that, we will construct a common privilege escalation payload.

# KASLR Bypass

The exploit itself is single bit write only, we did not construct any leak primitives.
In order to get a kernel pointer to bypass KASLR, we will adapt timing side channels
for simplicity reasons.
While PTI is not enabled, this works very well in practice.

The code for that is adapted from https://github.com/IAIK/prefetch/blob/master/cacheutils.h

# General Notes on the Exploit

The exploit makes heavy use of multiprocessing in order to simplify the use
of the network namespaces (recall we use one network namespace for each QFQ qdisc we
create.)

The main function performs coordination of the child processes.
The children will notify the parent through a simple wait based event system.
Qdiscs and spraying of fake classifiers are handled by child threads in `bug_worker()`.
We will select one of those workers to trigger the vulnerability, the others
will try to trigger RIP control.
If the bitflip failed, we will notice that we do not have root privileges.
Besides that, nothing is in an unstable state and we can try again.

Finally note that the exploit does not make use of any netlink library or the like.
Therefor, you may notice that the code related to netlink is quite verbose.
Reasons for that are unknown (maybe I did not know how to use the libraries.)

## Stability

The main stability problem is the initial heap spray where we try to achieve a three-way
aligned layout in `dyn-kmalloc-8192`.
In order to improve the reliablity of this step, we pin the orchestration to
a dedicated CPU while the workers (that perform the spray), are pinned to another
one.
This greatly increases the likeylhood of hitting the correct layout, however
chances are still quite low (~10%)

Overall this contributes to an observed stability of about 5%.

Finally, one should note that the exploit is not performing a decent
post-exploitation cleanup.
The QFQ qdisc class which triggered the vulnerability is not properly cleaned up, thus
as soon as the timers for dequeue operations fire, the kernel will likely
panic.
